Spectral Norm => NO PIX NORM + NO Scaled
NO PROGRESSION => RESIDUAL
BatchNorm + D == bad
TODOs in the code

condition:
    handle class conditioning data, generator, discriminator, inference
    instead of bn(w=emb_l(y)); bn(w=linear_l(emb(y))||z_l) -> make sure zero centerd and one centred
    report text as condition?
plugin:
    picture: top_generated, bottom 5 nearest neighbors in feature_space of D / feature_space of Inception / MSE
    gif(z1 -> z2)
    gif(const_z over epochs)
Z:
    uses different z chunks for different layers [for each block, uses the same z_chunk]
    per channel noise * learned weight after each conv
    ConditionalNormFunc(AdaIn, LayerNorm, BatchNorm) * (Ci / Fi(Zi,C) / Fi(Z0,C) / F0(Zi,Ci) / F0(Z0,Ci)) || (Fi(Zi) / Fi(Z0) / None)
Up/Down:
    Bilinear instead of NN
biggan:
    increase number of channels by 50%
    2 d iters, 5e-5 lr for G and 2e-4 for D; adam (0, 0.999)
exp:
    train arl-eeg on a subset
    plot the loss values
    aggregation graphs (like the eeg paper) in freq domain
    condition interpolation * Z(*chunks) interpolation
    D(x) as supervised weight
    connection net F(D_intermediate(x)) = z
    "one in the batch" conditioning
    240Hz
    more channels
    FID-IS AuC for truncation trick
    G_1(Z) = o1, o2, o3, o4 -> F(o1,o2,o3) = o4
inception:
    https://www.isip.piconepress.com/projects/tuh_eeg/downloads/tuh_eeg_abnormal/v2.0.0/
        O(30G), two classes based on report file(larger) => like our labels
