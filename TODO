Addition:
    experiment manager and hyper param search(Define ParamSearchSpace)

Validation:
    Alish Features
    d(concatenated parts) == fake
    https://github.com/eugenium/MMD/blob/master/mmd.py => (this is the 3way mode)work with fft
    Use validation result
Classification:
    ChronoNetStyleNetwork
    https://www.isip.piconepress.com/projects/tuh_eeg/downloads/tuh_eeg_events/v1.0.0/
    https://www.isip.piconepress.com/projects/tuh_eeg/downloads/tuh_eeg_epilepsy/current/
    https://www.isip.piconepress.com/projects/tuh_eeg/downloads/tuh_eeg_abnormal/v2.0.0/
Experiment:
    connection network
    differential privacy training
    test on audio
    sample-rnn + trained discriminator
    Recurrent => recurrent layers with a lipschitz regularizers(read the SN paper + orthogonal rnns)
    progressive dilated mode(Wavenet/TCN/DRNN)
        Z(2xFreq)|NewLayer|OldLayer|Fake ; Data(2xFreq)|NewLayer|OldLayer|Pred
        AutoRegressive
        Alpha Meaning
            at last layer(repeat vs get output of net)
            at first layer, get z directly or from the new layer
Condition:
    ConditionalBatchNorm
    On:
        User Embedding
        Easy meta-data(age, sex)
        All the data
    Loss:
        SemiSupervised InfoGAN(github.com/spurra/ss-infogan)
        AcGan(github.com/znxlwm/pytorch-generative-model-collections/blob/master/ACGAN.py)
        Activation Maximization(github.com/ZhimingZhou/AM-GAN)
        Class Splitting GAN(github.com/CIFASIS/splitting_gan)
        Projection(yW . x)(github.com/pfnet-research/sngan_projection)
InfiniteSeqLen:
    Freez D and swap first linear of G with a conv => not consistent => must defreeze D and retrain everything
    Mabye, giving 0,0,0,Z,0,0,0,Z,0,0,0,Z,0,0,0 will work? => middle outputs must be halved => is not consistent even with slerp
    G1(z)=o1,o2,o3,o4 so we can have a F(o1,o2,o3)=o4 and H(o2,o3,o4)=o1 + DropOut => extend this is VAE like output
    Use the connection net to make another gan over sequences of Z! :D
