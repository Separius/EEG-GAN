# python train.py --exp_name xxx --config_file defaults.yml --load_dataset results/data256.pkl --cuda_device 0

#result_dir: 'results'
#exp_name: ''
#lr_rampup_kimg: 50
#G_lr_max: 0.001
#D_lr_max: 0.001
#total_kimg: 4000
#resume_network: ''
#resume_time: 0
#num_data_workers: 3
#random_seed: 1337
#grad_lambda: 10.0
#iwass_epsilon: 0.001
#save_dataset: ''
#load_dataset: ''
loss_type: 'wgan_gp' # wgan_gp, wgan_ct, hinge
#cuda_device: 0
validation_split: 0
#LAMBDA_2: 2
optimizer: 'adam' # adam, amsgrad, ttur
#config_file: null
#verbose: false
fmap_base: 2048
fmap_max: 256
fmap_min: 64
equalized: true
kernel_size: 3
inception: false
self_attention_layer: null
self_attention_size: 32
#drnn: false
progression_scale: 2

#Trainer.grad_clip: null #null or a float
Trainer.D_training_repeats: 1
#Trainer.tick_kimg_default: 5
#Trainer.resume_nimg: 0

Generator.latent_size: 256
Generator.upsample: 'linear' #linear, nearest
#Generator.normalize_latents: true
#Generator.pixelnorm: true
#Generator.activation: 'lrelu' #prelu, lrelu, relu, relu6, elu
Generator.dropout: 0.1
Generator.residual: false
Generator.do_mode: 'mul' #mul, drop, prop
Generator.spectral_norm: false
Generator.ch_by_ch: false
Generator.normalization: null #null, batch_norm, layer_norm, weight_norm

Discriminator.downsample: 'average' #average, stride
Discriminator.residual: false
#Discriminator.activation: 'lrelu'
Discriminator.dropout: 0.1
Discriminator.do_mode: 'mul'
Discriminator.spectral_norm: false
Discriminator.phase_shuffle: 0
Discriminator.temporal_stats: false
Discriminator.num_stat_channels: 1
Discriminator.normalization: null #null, batch_norm, layer_norm, weight_norm
#Discriminator.pixelnorm: false

DepthManager.attention_start_depth: null
DepthManager.attention_transition_kimg: 200
#DepthManager.depth_offset: 0
#DepthManager.minibatch_default: 64
#DepthManager.minibatch_overrides: {6: 32, 7: 32, 8: 16}  # starts from depth_offset+1
#DepthManager.tick_kimg_overrides: {4: 4, 5: 3, 6: 2, 7: 1, 8: 1}  # starts from depth_offset+1
#DepthManager.lod_training_kimg: 400
#DepthManager.lod_training_kimg_overrides: {1: 250, 2: 250, 3: 300, 4: 350}  # starts from depth_offset+1
#DepthManager.lod_transition_kimg: 100
#DepthManager.lod_transition_kimg_overrides: {1: 50, 2: 60, 3: 80, 4: 90}  # starts from depth_offset+1

#SaverPlugin.keep_old_checkpoints: true
#SaverPlugin.network_snapshot_ticks: 50
SaverPlugin.use_3way_test: false

#OutputGenerator.samples_count: 8
#OutputGenerator.output_snapshot_ticks: 10

#GifGenerator.num_frames: 30
#GifGenerator.fps: 5

#Validator.output_snapshot_ticks: 20

#MyDataset.dir_path: './data/eeg'
#MyDataset.num_files: 860
MyDataset.seq_len: 256
#MyDataset.stride: 0.5
#MyDataset.max_freq: 80
#MyDataset.num_channels: 5
#MyDataset.per_user: true
#MyDataset.use_abs: false
MyDataset.model_dataset_depth_offset: 2 # start from 4x4 instead of 1x1

DilatedGenerator.latent_size: 256
DilatedGenerator.normalize_latents: true
DilatedGenerator.pixelnorm: true
DilatedGenerator.activation: 'lrelu'
DilatedGenerator.dropout: 0.1
DilatedGenerator.do_mode: 'mul'
DilatedGenerator.spectral_norm: false
DilatedGenerator.ch_by_ch: false
DilatedGenerator.normalization: null
DilatedGenerator.recurrent_dropout: 0.1
DilatedGenerator.bidir: false
DilatedGenerator.n_layers: 2
DilatedGenerator.cell_type: 'gru'

DilatedDiscriminator.activation: 'lrelu'
DilatedDiscriminator.dropout: 0.1
DilatedDiscriminator.do_mode: 'mul'
DilatedDiscriminator.spectral_norm: false
DilatedDiscriminator.normalization: null
DilatedDiscriminator.recurrent_dropout: 0.1
DilatedDiscriminator.bidir: false
DilatedDiscriminator.n_layers: 2
DilatedDiscriminator.cell_type: 'gru'
